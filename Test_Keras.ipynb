{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6ee450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "C:\\Users\\Wert\\AppData\\Local\\Temp\\ipykernel_14576\\4110586565.py:2: SyntaxWarning: invalid escape sequence '\\m'\n",
      "  loaded_model = keras.models.load_model('modelos\\my_model.keras')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "loaded_model = keras.models.load_model('modelos\\my_model.keras') \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac48d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Wert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Wert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wert\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "def stopWords(tokens):\n",
    "  a = set(stopwords.words(\"english\"))\n",
    "  text1 = [x.lower() for x in tokens]\n",
    "  sws = [x for x in text1 if x not in a]\n",
    "  return sws\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "def stemming(tokens):\n",
    "  pst = PorterStemmer()\n",
    "  text = []\n",
    "  for word in tokens:\n",
    "    text.append(pst.stem(word))\n",
    "  return text\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "def tokenization(text):\n",
    "  tokens = word_tokenize(text.lower())\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf22a4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [midnight, shadow, breathtak, masterpiec, ling...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = {\"text\":[\"Midnight Shadows is a breathtaking masterpiece that lingers in your mind long after the credits roll. From the very first frame, the film pulls you into its richly textured world with stunning cinematography that paints every scene like a moving work of art. The lead actor delivers a career-defining performance, balancing raw vulnerability with magnetic intensity, while the supporting cast elevates every moment with nuanced, unforgettable portrayals. The screenplay is a revelation—layered with profound themes and razor-sharp dialogue that crackles with authenticity. Each plot twist lands with precision, keeping you enthralled as the story unfolds with masterful pacing.\"]}\n",
    "df = pd.DataFrame(data)\n",
    "df[\"text\"] = df[\"text\"].apply(tokenization)\n",
    "df[\"text\"] = df[\"text\"].apply(stopWords)\n",
    "df[\"text\"] = df[\"text\"].apply(stemming)\n",
    "print(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c500ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00106158]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=200)\n",
    "tokenizer.fit_on_texts(df[\"text\"])\n",
    "secuencia_nueva = tokenizer.texts_to_sequences(df[\"text\"])\n",
    "sequence_length = loaded_model.input_shape[1] \n",
    "secuencia_padding_nueva = pad_sequences(secuencia_nueva, maxlen=sequence_length)\n",
    "resul = loaded_model.predict(secuencia_padding_nueva)\n",
    "resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e67e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Wert\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf2onnx\\tf_loader.py:68: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Wert\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf2onnx\\tf_loader.py:72: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rewriter <function rewrite_constant_fold at 0x000001362C3E6F20>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n",
      "rewriter <function rewrite_constant_fold at 0x000001362C3E6F20>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n",
      "rewriter <function rewrite_constant_fold at 0x000001362C3E6F20>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n",
      "rewriter <function rewrite_constant_fold at 0x000001362C3E6F20>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n",
      "rewriter <function rewrite_constant_fold at 0x000001362C3E6F20>: exception `np.cast` was removed in the NumPy 2.0 release. Use `np.asarray(arr, dtype=dtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import numpy as np\n",
    "from tf2onnx.convert import from_keras\n",
    "\n",
    "\n",
    "try:\n",
    "    output_names = [output.name for output in loaded_model.outputs]\n",
    "    setattr(loaded_model, 'output_names', output_names)\n",
    "except AttributeError:\n",
    "    print(\"Could not get names from model.outputs, using default name 'output'.\")\n",
    "    setattr(loaded_model, 'output_names', ['output'])\n",
    "\n",
    "\n",
    "input_signature = [tf.TensorSpec(shape=(None, sequence_length), dtype=tf.int32, name=\"input_sequences\")]\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(\n",
    "    loaded_model,\n",
    "    input_signature=input_signature,\n",
    "    opset=13,\n",
    "    output_path='modelo.onnx'\n",
    ")\n",
    "\n",
    "#onnx_model = tf2onnx.convert.from_keras(loaded_model, output_path='modelo.onnx')\n",
    "\n",
    "onnx.save_model(onnx_model,'modelo.onnx')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
